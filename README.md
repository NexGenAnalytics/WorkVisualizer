# Work Visualizer

## Contents

Currently, this repository contains the following directories and files:

1. `caliper.config`: This is the configuration file that will be used to generate the data dumps prior to analysis and visualization. Instructions for use are included below.

2. `app`: This directory contains the the code for the web app.

3. `mockups/`: This directory contains sample mock-ups for the end result of the Work Visualizer.

4. `data/`: This directory contains data generated by running various executables with the configuration file.

5. `scripts/`: This directory contains Python scripts for plotting and analyzing the generated data.

6. `plots/`: This directory contains plots that show various configurations of calls over time.

7. `hierarchies/`: This directory contains the JSON necessary to create a D3 call tree.

## Data

These instructions explain how to generate a data dump for any given application.

The steps assume that the top-level of the Work Visualizer repository has been exported to `$WORKVIZ_DIR`.

1. Install [Caliper](https://github.com/LLNL/Caliper) and add `bin/cali-query` to `$PATH`
_Note: At least for the moment, Caliper must be installed in Debug mode._

2. Export the following environment variables

```
export KOKKOS_TOOLS_LIBS=/path/to/libcaliper.so
export CALI_CONFIG_FILE=${WORKVIZ_DIR}/caliper.config
```

3. Run an executable that uses Kokkos
   - This will automatically generate `all-data-<mpi.rank>.cali` files in the directory where you ran the executable (one per rank).

4. Merge these `*.cali` files into a single JSON and move the JSON to the Work Visualizer's `data` directory:

```sh
cali-query -q "SELECT * FORMAT json" *.cali | tee <filename>.json
mv <filename>.json ${WORKVIZ_DIR}/data
```

The scripts look for the following naming convention for `<filename>`:
```sh
<app>_<num-procs>p_<num-steps>s(_<misc>).json
```
- `<app>`: Any identifier for the executable that generated the data. The following app identifiers are automatically recognized (so the full app name will be output on the plots).
  - `em` -> `MiniEM`
  - `mpm` -> `ExaMPM`
  - `md` -> `ExaMiniMD`

- `<num-procs>`: The number of MPI ranks that the executable was run with
- `<num-steps>`: The number of timesteps that the executable was run for
- `<misc>`: Any other identifying information (not required by the scripts)

## App

These instructions explain how to get the WorkVisualizer webapp running locally.

1. Install Node.js
```sh
sudo apt update
sudo apt install nodejs
```

2. Install Node Version Manager (`nvm`)
```sh
curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.38.0/install.sh | bash
# Close and reopen terminal, or run:
source ~/.bashrc
```

3. Install Node.js verison >= 20
```sh
nvm install 20
nvm use 20
```

4. Install necessary Python packages
```sh
pip install -r ${WORKVIZ_DIR}/app/workvisualizer/requirements.txt
```

5. From the `${WORKVIZ_DIR}/app/workvisualizer` directory, run:
```sh
npm install
```

6. In one terminal instance, run
```sh
cd ${WORKVIZ_DIR}/app/workvisualizer/api
uvicorn main:app --reload
```

7. In a separate terminal, run

```sh
cd ${WORKVIZ_DIR}/app/workvisualizer
npm run dev
```

You will see something like:

```
> workvisualizer@0.1.0 dev
> next dev

  ▲ Next.js 14.2.3
  - Local:        http://localhost:3000

 ✓ Starting...
 ✓ Ready in 1983ms
 ○ Compiling / ...
 ✓ Compiled / in 7.7s (3639 modules)
 GET / 200 in 8100ms
 ✓ Compiled in 374ms (1686 modules)
 ○ Compiling /favicon.ico ...
 ✓ Compiled /dashboard in 2.5s (1974 modules)
 ✓ Compiled in 1835ms (2242 modules)
 GET /dashboard 200 in 2957ms
 GET /favicon.ico 200 in 6ms

```

The WorkVisualizer will be available at the provided local address (in this case, `http://localhost:3000`).


## Scripts

Below are explanations of the scripts found in the `scripts/` directory.

### 1. `plot_all_data.py`

The end goal of this script is to determine 1) the period of any repeating phase of the program and 2) the number of iterations within that phase.

This information is written out on the final plot, as well as to `stdout`.

#### Behind the Scenes

The plotting script takes in the entire Caliper data dump for all ranks and all functions (both Kokkos and MPI calls).

Various filtering steps are implemented to cull the data:
1. Isolate the most common functions (ie the top x% most frequently-called functions)
2. From these, select the most periodic functions (those with the strongest peak-to-mean (PTM) ratio in their FFT plots)
3. From these, select the functions with the most similar period.

This is the period is used to estimate the number of iterations.

#### Steps to Plot

1. Generate the data dump (see above) and store in `data/`

2. Run the plotting script

The most basic call is:

```
python plotting_scripts/plot_all_data.py -i data/<filename>.json
```

A number of other parameters exist as well:

```
-i    <INPUT>          The input JSON file (this one's not optional)
-s    <SAVE>           Saves results to the plots directory.

-a    <ALL>            Plots all functions instead of just periodic ones
-f    <FILTERED>       Plots only the filtered functions (top 2% most-called functions)
-v    <VERTICAL>       Outputs the plot vertically.
-sort <SORT>           Sort by `path`, `call` or `rank`

-p    <PROC>           The processor to be plotted (one processor is plotted)
-t    <TARGET>         The processor to be colored (all processors are plotted)

-dt   <DRAW_TIMESTEP>  Draws the timesteps on the final plot.
-dm   <DRAW_MACROLOOP> Draws the macro-loops on the final plot.

-b    <BIN_COUNT>      The number of bins to use when discretizing for
                       frequency analysis.
```

Here is an example of the final plot (generated with Mini-EM on 4 processors and over 100 timesteps).
![Screenshot from 2024-04-19 15-40-37](https://github.com/NexGenAnalytics/WorkVisualizer/assets/132086024/4d0f3cc3-b681-43a3-be53-92b24d7f8940)


### 2. `create_hierarchy.py`

This script takes in the entire Caliper data dump and outputs a JSON that is compatible with the D3 call tree example ([link](https://observablehq.com/d/273ba128f4494a5c)).

Usage is simple. Generate the data (see above) and then run:

```
python scripts/create_function_tree.py -i data/<filename>.json
```

The resulting JSON (`*_d3_hierarchy.json`) is written to the `hierarchy/` directory.

### 3. `prune_json.py`

#### Data Generation
This script takes in the Caliper data for a single rank. During the data collection, run

```sh
cali-query -q "SELECT * FORMAT json" alltrace-0.cali | tee <filename>.json
mv <filename>.json ${WORKVIZ_DIR}/data
```

(The difference is replacing `*.cali` with the rank-specific .cali file.) Ensure that the resulting JSON `filename` is named appropriately.

For convention, keep the same naming pattern but replace `<n_procs>p` with `<rank>r`.

For example:

```sh
<app>_<rank>r_<num-steps>s(_<misc>).json # template
em_0r_100s_trace.json                    # example with MiniEM
```

As before, move the resulting JSON into the WorkVisualizer/data directory.

#### Running the Script

Run the following command:
```sh
python scripts/prune_json.py -i data/<filename>
```

This will generate a new file in `data/<APP-NAME>` with the pruned JSON.
